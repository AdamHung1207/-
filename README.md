在GitHub上找了一輪，滿多連線至台灣證交所要爬蟲的資料都會執行錯誤，也很懶得找原作者詢問為什麼，問了ChatGPT跟其它AI也是鬼打牆。

那我就自己叫ChatGPT寫一個吧！！！

===============我是分隔線==============

![image](https://github.com/user-attachments/assets/0bf9b25f-d199-4389-a530-bf582d7c215c)

首先，我稍微修正了跟上一版不同的地方，原本是抓取當天執行時，往回推15年的歷史資料。

也就是你2025/04/01執行，就會從2010/04/01開始抓取資料，這邊改成起始點是從2020/01/01開始，有25年以上的資料要做任何的分析應該都算具有較高的參考價值 .. 吧？

第二，我修正了原本台股裡名稱*字號的KY股，造成下載時無法辨識，所以我就去把.csv裡的符號手動砍掉了。

第三，我發現原本的檔案在亞力及美律會無法自動下載，看了.csv也沒什麼錯誤，所以我請AI幫我把原本只有1.完整下載、2.更新，多增加了3.手動補充下載以及4.結束程式。

會這樣是第一次運作後，每手動下載完一次，終端機就會卡在最後下載的檔案位置，也做不了什麼，就請AI幫我在執行完後要記得回到選單頁面。

![image](https://github.com/user-attachments/assets/8c6428f5-78c7-493d-b96a-0309aef59f6b)

第四，我發現這個碁不知道為什麼原本可以，後來又不行了，所以下載完了還是請各位記得自己回頭去看一下執行上有沒有錯誤。

![image](https://github.com/user-attachments/assets/44da6711-4861-4fe0-9ac3-49a121b8565d)

第五，原本的亞力沒有，我有先用手動下載，然後再執行更新時就會出現這樣的提示訊息了。

第六，原本的隨機2~10秒拔除，好像沒有管制欸，那就照黑鬼東說的，想快！就不要被速度限制了自己，沒有煞車就快了，拔掉吧！！！！！

===============我是分隔線==============

# 設定存放 CSV 檔案的資料夾名稱
DATA_FOLDER = "TW_Stock"

# 確保資料夾存在
os.makedirs(DATA_FOLDER, exist_ok=True)

確保執行下，與main.py的目錄下還有一個TW_Stock的資料夾，用來存放.csv。

# 讀取 CSV 檔案，確保有 "ticker" 和 "name" 欄位
stock_list = pd.read_csv("stock_list.csv", encoding="utf-8-sig")

台股各股代號及名稱是我是取stock_list，你想取別的名字自己改，裡面的title也可以改你想要的，不會的叫AI幫你改。

===============我是分隔線==============

不一定會再更新，也有可能API哪天就會被擋爬蟲了，會不會發生我也不知道，有影響到我再說。

再視情況要不要來更新。
